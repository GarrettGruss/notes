# software quality metrics

- Size (complexity etc.)
- Time
- Effort
- Reliability (quality etc.)
- Productivity

## module 1: Overall framework

- Goal, Questions, metrics (GQM)
    - What it is, background, and relation to ESE
- Experience Factory (EF)
- Quality improvement paradigm (QIP)
- Other frameworks

## module 1: Mathematical foundation

- Measurement theory
- Types and levels of measurement

## module 2 & 3: External metrics

- Quality: reliability, safety, dependability, usability, etc.
- Cost, time, schedule, activity, environment, etc.
- Areas and contexts: Public-Private Partnership

## module 2 & 3: Internal metrics

- Complexity
- Dimensions and classification of complexity metrics

## module 2 & 3: Defect metrics

- Internal and external view

## module 2 & 3: Relations, classification, usage

## module 4: Empirical evaluation

- Leads to formal model
- Data and statistical analysis
- Other empirical evidence/corroboration
    - evidence to confirm or support finding

## module 4: Formal model

- Historical development
- Tian-Zelkowitz model
- Other recent development ( if we have time)

## module 5: Advance Topics

- Results analysis and hypothesis testing
- Using metrics (Koru-Tian)
- Bigger picture of ESE
- Main ideas, guidelines, applications
- Integrated approach
- Putnam/Myers 5 core metrics
- New applications/development
- Traditional: commercial, telecom, etc.
- New: net-centric, Service-oriented Architecture (SOA), cloud, etc.

# Key components of software engineering

- Methods and Processes
- Formal Foundations (Math/Theory)
- Experimentation (Scientific)

# Capturing Defects / Measurement Framework

The goal of a system is meet specific behavior. System boundaries should be established to identify what constitues a defect. The system boundaries will guide what data should be captured. Defect trends need to be captured to produce actionable insights from a model. Defect should be traceable. At a minimum, you should capture:

- The requirement or feature the defect is related to
- Configuration when the defect occured
    - Revision / release of the code (Tags)
    - System configuration
- Inputs to the system
- System state
- Severity of the defect

## Measurement Framework

**Goal-Question-Metric Paradigm (QGM)**: What is the goal of the study, what are the questions related to the study, what are the metrics for answering questions.

**Quality Improvement Paradigm (QIP)**: Based on goal-question-metric framework.

Whenever a change is made to a software baseline, the changes and impacts should be quantified.

**Experience Factory**:

- 

# Measurement in Emperical Software Engineering (ESE)

**Definition**: Context and measurement theory
**Gathering**: Data collection
**Analysis/Follow up**: Analysis, presentation, interpretation

## Measurement Theory

- Formalization of measurement
    * R: relation
    * f(x): measurement as functional mapping
    * aRb <-> f(a) > f(b)

## MEasurement Evaluation

Evaluation criteria:

- Are theyp roperly defined
- Are theyp properly used
- Do they lead to any useful results

Based on evaluation

- Decide which metrics to select
- Propose new ones
- Under what context should they be used

Evaluation of new metrics

- Identify scope of metric
- Demonstrate use and usefulness
- Identify bias

Empirical evaluation of metrics

- 

## Types of metrics evaluation